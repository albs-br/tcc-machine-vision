{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents a prototypical python 3 implementation for a without safeguards, without asserts, with fixed paramterized model. For larger data sets it is advised to store intermediate results, e.g. as pickle files.\n",
    "\n",
    "Theory https://towardsdatascience.com/effortlessly-recommending-similar-images-b65aff6aabfb\n",
    "\n",
    "\n",
    "\n",
    "# Redimensionando\n",
    "\n",
    "Neste primeiro passo pegamos todas as imagens (.jpg) no diretório de entrada (inputDir) e as normalizamos \n",
    "para o tamanho 224x224, necessário para o PyTorch com resnet18. As imagens redimensionadas são salvas no\n",
    "diretório inputDirCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# needed input dimensions for the CNN\n",
    "inputDim = (224,224)\n",
    "inputDir = \"originalImages\"\n",
    "inputDirCNN = \"inputImagesCNN\"\n",
    "searchDir = \"searchDir\"\n",
    "\n",
    "os.makedirs(inputDirCNN, exist_ok = True)\n",
    "\n",
    "# clear inputDirCnn folder\n",
    "for f in os.listdir(inputDirCNN):\n",
    "    if not f.endswith(\".jpg\"):\n",
    "        continue\n",
    "    os.remove(os.path.join(inputDirCNN, f))\n",
    "\n",
    "\n",
    "\n",
    "def resizeAndSaveToInputDirCNN(inputDir, imageName, inputDirCNN):\n",
    "    transformationForCNNInput = transforms.Compose([transforms.Resize(inputDim)])\n",
    "    \n",
    "    I = Image.open(os.path.join(inputDir, imageName))\n",
    "    newI = transformationForCNNInput(I)\n",
    "\n",
    "    # copy the rotation information metadata from original image and save, else your transformed images may be rotated\n",
    "    if \"exif\" in I.info:\n",
    "        exif = I.info['exif']\n",
    "        newI.save(os.path.join(inputDirCNN, imageName), exif=exif)\n",
    "    else:\n",
    "        newI.save(os.path.join(inputDirCNN, imageName))\n",
    "    \n",
    "    newI.close()\n",
    "    I.close()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "for imageName in os.listdir(inputDir):\n",
    "    resizeAndSaveToInputDirCNN(inputDir, imageName, inputDirCNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando os vetores de características com Resnet18\n",
    "\n",
    "Calculando os vetores de características (features) das imagens com resnet18 usando CPU (ao invés de GPU). A entrada é normalizada para os valores médios e desvio padrão da ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "\n",
    "# for this prototype we use no gpu, cuda= False and as model resnet18 to obtain feature vectors\n",
    "\n",
    "class Img2VecResnet18():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.numberFeatures = 512\n",
    "        self.modelName = \"resnet-18\"\n",
    "        self.model, self.featureLayer = self.getFeatureLayer()\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "        \n",
    "        # normalize the resized images as expected by resnet18\n",
    "        # [0.485, 0.456, 0.406] --> normalized mean value of ImageNet, [0.229, 0.224, 0.225] std of ImageNet\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "    def getVec(self, img):\n",
    "        image = self.normalize(self.toTensor(img)).unsqueeze(0).to(self.device)\n",
    "        embedding = torch.zeros(1, self.numberFeatures, 1, 1)\n",
    "\n",
    "        def copyData(m, i, o): embedding.copy_(o.data)\n",
    "\n",
    "        h = self.featureLayer.register_forward_hook(copyData)\n",
    "        self.model(image)\n",
    "        h.remove()\n",
    "\n",
    "        return embedding.numpy()[0, :, 0, 0]\n",
    "\n",
    "    def getFeatureLayer(self):\n",
    "        \n",
    "        cnnModel = models.resnet18(pretrained=True)\n",
    "        layer = cnnModel._modules.get('avgpool')\n",
    "        self.layer_output_size = 512\n",
    "        \n",
    "        return cnnModel, layer\n",
    "        \n",
    "\n",
    "def convertImageToFeatureVector(image, vectors):\n",
    "    I = Image.open(os.path.join(inputDirCNN, image))\n",
    "    vec = img2vec.getVec(I)\n",
    "    vectors[image] = vec\n",
    "    I.close() \n",
    "    return\n",
    "        \n",
    "# generate vectors for all the images in the set\n",
    "img2vec = Img2VecResnet18() \n",
    "\n",
    "allVectors = {}\n",
    "print(\"Converting images to feature vectors:\")\n",
    "for image in tqdm(os.listdir(inputDirCNN)):\n",
    "    convertImageToFeatureVector(image, allVectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similaridade de cosseno (Cosine similarity)\n",
    "Calculando para cada vetor a similaridade de cosseno para os outros vetores.\n",
    "OBS: com milhares de imagens essa matriz pode se tornar imensa e ineficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# now let us define a function that calculates the cosine similarity entries in the similarity matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getSimilarityMatrix(vectors):\n",
    "    v = np.array(list(vectors.values())).T\n",
    "    sim = np.inner(v.T, v.T) / ((np.linalg.norm(v, axis=0).reshape(-1,1)) * ((np.linalg.norm(v, axis=0).reshape(-1,1)).T))\n",
    "    keys = list(vectors.keys())\n",
    "    matrix = pd.DataFrame(sim, columns = keys, index = keys)\n",
    "    \n",
    "    return matrix\n",
    "        \n",
    "similarityMatrix = getSimilarityMatrix(allVectors)\n",
    "\n",
    "# print(similarityMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparando as listas de top-k mais semelhantes\n",
    "A partir da matriz de similaridade, armazenamos em outra estrutura de dados as k imagens mais semelhantes à cada uma do dataset de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from numpy.testing import assert_almost_equal\n",
    "import pickle\n",
    "\n",
    "k = 5 # the number of top similar images to be stored\n",
    "\n",
    "similarNames = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "similarValues = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "\n",
    "for j in tqdm(range(similarityMatrix.shape[0])):\n",
    "    kSimilar = similarityMatrix.iloc[j, :].sort_values(ascending = False).head(k)\n",
    "    similarNames.iloc[j, :] = list(kSimilar.index)\n",
    "    similarValues.iloc[j, :] = kSimilar.values\n",
    "\n",
    "similarNames.to_pickle(\"similarNames.pkl\")\n",
    "similarValues.to_pickle(\"similarValues.pkl\")\n",
    "\n",
    "# print(similarNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando a similaridade entre as imagens de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# take some examples from the provided image set and plot\n",
    "# inputImages = [\"trees0.jpg\", \"camper0.jpg\", \"buildings0.jpg\", \"donkey0.jpg\", \"donkey_search.jpg\", \"kombi_search.jpg\"]\n",
    "# inputImages = [\"20150703_0805_34.jpg\" , \"20150703_0825_6.jpg\",\n",
    "#                 \"busy 20150703_0840_2.jpg\", \"20150703_0830_24.jpg\"]\n",
    "# inputImages = [\"20150703_0820_39.jpg\", \"busy 20150703_0920_14.jpg\"] # search images\n",
    "\n",
    "inputImages = []\n",
    "for f in os.listdir(inputDirCNN):\n",
    "    if not f.endswith(\".jpg\"):\n",
    "        continue\n",
    "    inputImages.append(f)\n",
    "\n",
    "numCol = 5\n",
    "numRow = 1\n",
    "\n",
    "def setAxes(ax, image, query = False, **kwargs):\n",
    "    value = kwargs.get(\"value\", None)\n",
    "    if query:\n",
    "        ax.set_xlabel(\"Query Image\\n{0}\".format(image[:12]), fontsize = 12, color = \"red\")\n",
    "    else:\n",
    "        ax.set_xlabel(\"Similarity {1:1.3f}\\n{0}\".format(image[:12],  value), fontsize = 12)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "def getSimilarImages(image, simNames, simVals):\n",
    "    if image in set(simNames.index):\n",
    "        imgs = list(simNames.loc[image, :])\n",
    "        vals = list(simVals.loc[image, :])\n",
    "        if image in imgs:\n",
    "            assert_almost_equal(max(vals), 1, decimal = 5)\n",
    "            imgs.remove(image)\n",
    "            vals.remove(max(vals))\n",
    "        return imgs, vals\n",
    "    else:\n",
    "        print(\"'{}' Unknown image\".format(image))\n",
    "        \n",
    "def plotSimilarImages(image, similarNames, similarValues):\n",
    "    simImages, simValues = getSimilarImages(image, similarNames, similarValues)\n",
    "    fig = plt.figure(figsize=(10, 20))\n",
    "    \n",
    "    # now plot the  most simliar images\n",
    "    for j in range(0, numCol*numRow):\n",
    "        ax = []\n",
    "        if j == 0:\n",
    "            if os.path.exists(os.path.join(inputDir, image)):\n",
    "                img = Image.open(os.path.join(inputDir, image))\n",
    "            else:\n",
    "                img = Image.open(os.path.join(searchDir, image))\n",
    "            ax = fig.add_subplot(numRow, numCol, 1)\n",
    "            setAxes(ax, image, query = True)\n",
    "        else:\n",
    "            img = Image.open(os.path.join(inputDir, simImages[j-1]))\n",
    "            ax.append(fig.add_subplot(numRow, numCol, j+1))\n",
    "            setAxes(ax[-1], simImages[j-1], value = simValues[j-1])\n",
    "        img = img.convert('RGB')\n",
    "        plt.imshow(img)\n",
    "        img.close()\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "for image in inputImages:\n",
    "    plotSimilarImages(image, similarNames, similarValues)\n",
    "    \n",
    "    \n",
    "#show search image\n",
    "# img = Image.open(os.path.join(searchDir, \"donkey_search.jpg\"))\n",
    "# plt.imshow(img)\n",
    "# img.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando com uma imagem de fora do Dataset de treinamento (caso de uso mais próximo do real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def BuscarImagensSemelhantes(searchImgName):\n",
    "    searchImg = Image.open(os.path.join(searchDir, searchImgName))\n",
    "\n",
    "    # resize and save to inputDirCNN\n",
    "    resizeAndSaveToInputDirCNN(searchDir, searchImgName, inputDirCNN)\n",
    "\n",
    "\n",
    "    convertImageToFeatureVector(searchImgName, allVectors)\n",
    "\n",
    "\n",
    "    similarityMatrix = getSimilarityMatrix(allVectors)\n",
    "\n",
    "    # prepareTopKLists(k, similarityMatrix)\n",
    "    newSimilarNames = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "    newSimilarValues = pd.DataFrame(index = similarityMatrix.index, columns = range(k))\n",
    "\n",
    "    for j in tqdm(range(similarityMatrix.shape[0])):\n",
    "        kSimilar = similarityMatrix.iloc[j, :].sort_values(ascending = False).head(k)\n",
    "        newSimilarNames.iloc[j, :] = list(kSimilar.index)\n",
    "        newSimilarValues.iloc[j, :] = kSimilar.values\n",
    "\n",
    "    plotSimilarImages(searchImgName, newSimilarNames, newSimilarValues)\n",
    "\n",
    "    allVectors.pop(searchImgName) # ponto e vírgula necessário para não imprimir a saída do comando\n",
    "    ; \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "for f in os.listdir(searchDir):\n",
    "    if not f.endswith(\".jpg\"):\n",
    "        continue\n",
    "    BuscarImagensSemelhantes(f)\n",
    "    \n",
    "# searchImgName = \"20150703_0820_39.jpg\"\n",
    "# #searchImgName = \"busy 20150703_0920_14.jpg\"\n",
    "# BuscarImagensSemelhantes(searchImgName)\n",
    "\n",
    "# total imagens: 128\n",
    "# tempo tota: 54.6 s\n",
    "# tempo por imagem: 0,42 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
